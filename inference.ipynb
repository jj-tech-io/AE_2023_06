{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_modules import *\n",
    "import my_config\n",
    "import time\n",
    "# K.clear_session()\n",
    "# os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "Found GPU at: /device:GPU:0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "if my_config.USE_GPU:\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    #set memory amount to half of GPU\n",
    "    if len(physical_devices) > 0:\n",
    "        for device in physical_devices:\n",
    "            print(\"Device:\", device)\n",
    "    else:\n",
    "        print(\"No GPU devices found.\")\n",
    "    # Set GPU memory growth\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "                \n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "        # Set environment variable for GPU memory allocation\n",
    "    os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "    # Test for GPU device name\n",
    "    name = tf.test.gpu_device_name()\n",
    "    if name != '/device:GPU:0':\n",
    "        raise SystemError('GPU device not found')\n",
    "    print('Found GPU at: {}'.format(name))\n",
    "    # Print the number of available GPUs\n",
    "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "else:\n",
    "    print(\"No GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m141_4k', 'm46_4k', 'm53_4k', 'm64_4k', 'm98_4k']\n",
      "models_4k\n",
      "TrainedModels\\316\\encoder.h5\n",
      "TrainedModels\\316\\decoder.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Loaded models\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "encoder_dense_0 (Dense)      (None, 75)                300       \n",
      "_________________________________________________________________\n",
      "encoder_dense_2 (Dense)      (None, 75)                5700      \n",
      "_________________________________________________________________\n",
      "encoder_output (Dense)       (None, 5)                 380       \n",
      "=================================================================\n",
      "Total params: 6,380\n",
      "Trainable params: 6,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Encoder summary:None\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 5)]               0         \n",
      "_________________________________________________________________\n",
      "decoder_dense_0 (Dense)      (None, 75)                450       \n",
      "_________________________________________________________________\n",
      "decoder_dense_2 (Dense)      (None, 75)                5700      \n",
      "_________________________________________________________________\n",
      "decoder_output (Dense)       (None, 3)                 228       \n",
      "=================================================================\n",
      "Total params: 6,378\n",
      "Trainable params: 6,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Decoder summary:None\n"
     ]
    }
   ],
   "source": [
    "image_paths = os.listdir(my_config.IMAGE_FOLDER)\n",
    "images = []\n",
    "names = []\n",
    "for image_path in image_paths:\n",
    "    folder_name = image_path.split('.')[0]\n",
    "    names.append(folder_name)\n",
    "    image_path = os.path.join(my_config.IMAGE_FOLDER, image_path)\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = np.array(image)\n",
    "    if np.max(image) > 1:\n",
    "        image = image/255.0\n",
    "    images.append(image)\n",
    "print(names)\n",
    "all_model_paths = []\n",
    "print(my_config.IMAGE_FOLDER)\n",
    "print(my_config.ENCODER_PATH)\n",
    "print(my_config.DECODER_PATH)\n",
    "\n",
    "encoder = load_model(my_config.ENCODER_PATH)\n",
    "decoder = load_model(my_config.DECODER_PATH)\n",
    "print(\"Loaded models\")\n",
    "print(\"Encoder summary:\" + str(encoder.summary()))\n",
    "print(\"Decoder summary:\" + str(decoder.summary()))\n",
    "def encode(img):\n",
    "    image = np.asarray(img).reshape(-1,3).astype('float32')\n",
    "    # pred_maps = encoder.predict(image)\n",
    "    start = time.time()\n",
    "    pred_maps = None\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        pred_maps = encoder.predict_on_batch(image)\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    return pred_maps, elapsed\n",
    " \n",
    "def decode(encoded):\n",
    "    # recovered = decoder.predict(encoded)\n",
    "    start = time.time()\n",
    "    recovered = None\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        recovered = decoder.predict_on_batch(encoded)\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    # recovered = np.clip(recovered, 0, 1)\n",
    "    return recovered, elapsed\n",
    "def calculate_deltaE(original, recovered):  # assuming this function is defined\n",
    "    WIDTH = original.shape[0]\n",
    "    HEIGHT = original.shape[1]\n",
    "    # Convert the images to the CAM02-UCS color space and calculate the delta E loss\n",
    "    if original.shape[0] != recovered.shape[0] or original.shape[1] != recovered.shape[1]:\n",
    "        print(\"original shape:\", original.shape)\n",
    "        print(\"recovered shape:\", recovered.shape)\n",
    "        print(\"original and recovered shape do not match\")\n",
    "        original = original.reshape((WIDTH, HEIGHT, 3))\n",
    "        recovered = recovered.reshape((WIDTH, HEIGHT, 3))\n",
    "    original_lab = colorspacious.cspace_convert(np.array(original), 'sRGB1', 'CAM02-UCS').reshape((WIDTH,HEIGHT,3))\n",
    "    recovered_lab = colorspacious.cspace_convert(np.array(recovered), 'sRGB1', 'CAM02-UCS').reshape((WIDTH,HEIGHT,3))\n",
    "    delta_e = np.sqrt(np.sum((original_lab - recovered_lab)**2, axis=2))\n",
    "    # Plot the delta E loss in the third subplot\n",
    "    return delta_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(5,5, figsize=(16,14))\n",
    "subjects_meta = ['m141_4k', 'm46_4k', 'm53_4k', 'm64_4k', 'm98_4k']\n",
    "idx = 0\n",
    "\n",
    "for image, folder_name in zip(images, names):\n",
    "    WIDTH = image.shape[0]\n",
    "    HEIGHT = image.shape[1]\n",
    "    image = np.asarray(image)\n",
    "    image_numpy = image.reshape((WIDTH, HEIGHT, 3))\n",
    "    pred_maps, encode_time = encode(image_numpy)\n",
    "    print(f\"shape of pred_maps: {pred_maps.shape}\")\n",
    "    Cm = np.asarray(pred_maps[:,0])\n",
    "    Ch = np.asarray(pred_maps[:,1])\n",
    "    Bm = np.asarray(pred_maps[:,2])\n",
    "    Bh = np.asarray(pred_maps[:,3])\n",
    "    T = np.asarray(pred_maps[:,4])\n",
    "    av_T = np.mean(T)\n",
    "    max_T = np.max(T)\n",
    "    min_T = np.min(T)\n",
    "    av_Cm = np.mean(Cm)\n",
    "    max_Cm = np.max(Cm)\n",
    "    min_Cm = np.min(Cm)\n",
    "    av_Ch = np.mean(Ch)\n",
    "    max_Ch = np.max(Ch)\n",
    "    min_Ch = np.min(Ch)\n",
    "    min_Bm = np.min(Bm)\n",
    "    max_Bm = np.max(Bm)\n",
    "    av_Bm = np.mean(Bm)\n",
    "    min_Bh = np.min(Bh)\n",
    "    max_Bh = np.max(Bh)\n",
    "    av_Bh = np.mean(Bh)\n",
    "    # result_string = f\"Cm: {av_Cm}, {max_Cm}, {min_Cm} | Ch: {av_Ch}, {max_Ch}, {min_Ch} | T: {av_T}, {max_T}, {min_T} | delta_e: {av_delta_e}, {max_delta_e}, {min_delta_e}\"\n",
    "    result_string = f\"Cm min: {min_Cm} Cm mean: {av_Cm}| Cm max: {max_Cm} | Ch min: {min_Ch} Ch mean: {av_Ch}| Ch max: {max_Ch} | T min: {min_T} T mean: {av_T}| T max: {max_T} | Bm min: {min_Bm} Bm mean: {av_Bm}| Bm max: {max_Bm} | Bh min: {min_Bh} Bh mean: {av_Bh}| Bh max: {max_Bh}\"\n",
    "    print(result_string)\n",
    "    pred_maps[:,0] = Cm*0.9\n",
    "    pred_maps[:,1] = Ch*0.9\n",
    "    pred_maps[:,2] = Bm\n",
    "    pred_maps[:,3] = Bh*0.8\n",
    "    pred_maps[:,4] = T*0.9\n",
    "    recovered, decode_time = decode(pred_maps)\n",
    "    print(f\"shape of recovered: {recovered.shape}\")\n",
    "    recovered = np.asarray(recovered).reshape((WIDTH, HEIGHT, 3))\n",
    "    # recovered_lab= colorspacious.cspace_convert(recovered, 'sRGB1', 'CAM02-UCS')\n",
    "    # recovered = np.asarray(decoded_increased_Cm).reshape((WIDTH, HEIGHT, 3))\n",
    "    plt.imshow(recovered)\n",
    "    plt.show()\n",
    "    #save the image \n",
    "    #print size of image\n",
    "    print(f\"size of image: {recovered.shape}\")\n",
    "    #max min pixel values\n",
    "    print(f\"max pixel value: {np.max(recovered)}\")\n",
    "    print(f\"min pixel value: {np.min(recovered)}\")\n",
    "    #clamp the values to 0-1\n",
    "    recovered = np.clip(recovered, 0, 1)\n",
    "    # experiment_name = input(\"Enter experiment name: \")\n",
    "    # file_NAME = f\"{experiment_name}_{subjects_meta[idx]}.png\"\n",
    "    # plt.imsave(file_NAME, recovered)\n",
    "    idx += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu_20230406",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
