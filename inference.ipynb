{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_modules import *\n",
    "import my_config\n",
    "K.clear_session()\n",
    "# os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "Found GPU at: /device:GPU:0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "if my_config.USE_GPU:\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    #set memory amount to half of GPU\n",
    "    if len(physical_devices) > 0:\n",
    "        for device in physical_devices:\n",
    "            print(\"Device:\", device)\n",
    "    else:\n",
    "        print(\"No GPU devices found.\")\n",
    "    # Set GPU memory growth\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "    # Test for GPU device name\n",
    "    name = tf.test.gpu_device_name()\n",
    "    if name != '/device:GPU:0':\n",
    "        raise SystemError('GPU device not found')\n",
    "    print('Found GPU at: {}'.format(name))\n",
    "    # Print the number of available GPUs\n",
    "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "else:\n",
    "    print(\"No GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m141_4k', 'm46_4k', 'm53_4k', 'm64_4k', 'm98_4k']\n",
      "models_4k\n",
      "TrainedModels\\316\\encoder.h5\n",
      "TrainedModels\\316\\decoder.h5\n"
     ]
    },
    {
     "ename": "AlreadyExistsError",
     "evalue": "Another metric with the same name already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAlreadyExistsError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[39mprint\u001b[39m(my_config\u001b[39m.\u001b[39mENCODER_PATH)\n\u001b[0;32m     17\u001b[0m \u001b[39mprint\u001b[39m(my_config\u001b[39m.\u001b[39mDECODER_PATH)\n\u001b[1;32m---> 18\u001b[0m encoder \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39mload_model(my_config\u001b[39m.\u001b[39mENCODER_PATH)\n\u001b[0;32m     19\u001b[0m decoder \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mload_model(my_config\u001b[39m.\u001b[39mDECODER_PATH)\n\u001b[0;32m     20\u001b[0m encoder_paths \u001b[39m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:62\u001b[0m, in \u001b[0;36mLazyLoader.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, item):\n\u001b[1;32m---> 62\u001b[0m   module \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_load()\n\u001b[0;32m     63\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(module, item)\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\tensorflow\\python\\util\\lazy_loader.py:45\u001b[0m, in \u001b[0;36mLazyLoader._load\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39m\"\"\"Load the module and insert it into the parent's globals.\"\"\"\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39m# Import the target module and insert it into the parent's namespace\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m module \u001b[39m=\u001b[39m importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__name__\u001b[39;49m)\n\u001b[0;32m     46\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_module_globals[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_local_name] \u001b[39m=\u001b[39m module\n\u001b[0;32m     48\u001b[0m \u001b[39m# Emit a warning if one was specified\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:972\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:972\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:972\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:986\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:680\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[1;34m(spec)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap_external>:850\u001b[0m, in \u001b[0;36mexec_module\u001b[1;34m(self, module)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:228\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\keras\\__init__.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m     24\u001b[0m \u001b[39m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\keras\\models\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\keras\\engine\\functional.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer_utils\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m input_layer \u001b[39mas\u001b[39;00m input_layer_module\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\keras\\engine\\base_layer.py:40\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m node \u001b[39mas\u001b[39;00m node_module\n\u001b[0;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m autocast_variable\n\u001b[1;32m---> 40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m loss_scale_optimizer\n\u001b[0;32m     41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m policy\n\u001b[0;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaved_model\u001b[39;00m \u001b[39mimport\u001b[39;00m layer_serialization\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\keras\\mixed_precision\\loss_scale_optimizer.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Contains the loss scaling optimizer class.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m optimizers\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m loss_scale \u001b[39mas\u001b[39;00m keras_loss_scale_module\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizer_v2\u001b[39;00m \u001b[39mimport\u001b[39;00m optimizer_v2\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\keras\\optimizers\\__init__.py:39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m \u001b[39mimport\u001b[39;00m rmsprop\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m \u001b[39mimport\u001b[39;00m sgd\n\u001b[1;32m---> 39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m adadelta \u001b[39mas\u001b[39;00m adadelta_legacy\n\u001b[0;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m adagrad \u001b[39mas\u001b[39;00m adagrad_legacy\n\u001b[0;32m     41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m adam \u001b[39mas\u001b[39;00m adam_legacy\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\keras\\optimizers\\legacy\\adadelta.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend_config\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m optimizer_v2\n\u001b[0;32m     23\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtf_export\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_export\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\keras\\optimizers\\legacy\\optimizer_v2.py:38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtf_export\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_export\n\u001b[1;32m---> 38\u001b[0m keras_optimizers_gauge \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49mmonitoring\u001b[39m.\u001b[39;49mBoolGauge(\n\u001b[0;32m     39\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m/tensorflow/api/keras/optimizers\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mkeras optimizer usage\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mmethod\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m     40\u001b[0m )\n\u001b[0;32m     42\u001b[0m _DEFAULT_VALID_DTYPES \u001b[39m=\u001b[39m \u001b[39mfrozenset\u001b[39m(\n\u001b[0;32m     43\u001b[0m     [\n\u001b[0;32m     44\u001b[0m         tf\u001b[39m.\u001b[39mfloat16,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m     ]\n\u001b[0;32m     51\u001b[0m )\n\u001b[0;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_deduplicate_indexed_slices\u001b[39m(values, indices):\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\tensorflow\\python\\eager\\monitoring.py:360\u001b[0m, in \u001b[0;36mBoolGauge.__init__\u001b[1;34m(self, name, description, *labels)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, description, \u001b[39m*\u001b[39mlabels):\n\u001b[0;32m    353\u001b[0m   \u001b[39m\"\"\"Creates a new BoolGauge.\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \n\u001b[0;32m    355\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[39m    *labels: The label list of the new metric.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m   \u001b[39msuper\u001b[39;49m(BoolGauge, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mBoolGauge\u001b[39;49m\u001b[39m'\u001b[39;49m, _bool_gauge_methods,\n\u001b[0;32m    361\u001b[0m                                   \u001b[39mlen\u001b[39;49m(labels), name, description, \u001b[39m*\u001b[39;49mlabels)\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\tensorflow\\python\\eager\\monitoring.py:135\u001b[0m, in \u001b[0;36mMetric.__init__\u001b[1;34m(self, metric_name, metric_methods, label_length, *args)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mif\u001b[39;00m label_length \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metric_methods):\n\u001b[0;32m    132\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCannot create \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m metric with label >= \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    133\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metric_name, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metric_methods)))\n\u001b[1;32m--> 135\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_metric_methods[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_label_length]\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs)\n",
      "\u001b[1;31mAlreadyExistsError\u001b[0m: Another metric with the same name already exists."
     ]
    }
   ],
   "source": [
    "image_paths = os.listdir(my_config.IMAGE_FOLDER)\n",
    "images = []\n",
    "names = []\n",
    "for image_path in image_paths:\n",
    "    folder_name = image_path.split('.')[0]\n",
    "    names.append(folder_name)\n",
    "    image_path = os.path.join(my_config.IMAGE_FOLDER, image_path)\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = np.array(image)\n",
    "    if np.max(image) > 1:\n",
    "        image = image/255.0\n",
    "    images.append(image)\n",
    "print(names)\n",
    "all_model_paths = []\n",
    "print(my_config.IMAGE_FOLDER)\n",
    "print(my_config.ENCODER_PATH)\n",
    "print(my_config.DECODER_PATH)\n",
    "encoder = tf.keras.models.load_model(my_config.ENCODER_PATH)\n",
    "decoder = tf.keras.models.load_model(my_config.DECODER_PATH)\n",
    "encoder_paths = []\n",
    "decoder_paths = []\n",
    "def encode(img):\n",
    "    image = np.asarray(img).reshape(-1,3).astype('float32')\n",
    "    # pred_maps = encoder.predict(image)\n",
    "    start = time.time()\n",
    "    with tf.device('/device:GPU:0') as device:\n",
    "        pred_maps = encoder.predict_on_batch(image)\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    return pred_maps, elapsed\n",
    " \n",
    "def decode(encoded):\n",
    "    # recovered = decoder.predict(encoded)\n",
    "    start = time.time()\n",
    "    with tf.device('/device:GPU:0') as device:\n",
    "        recovered = decoder.predict_on_batch(encoded)\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    # recovered = np.clip(recovered, 0, 1)\n",
    "    return recovered, elapsed\n",
    "def calculate_deltaE(original, recovered):  # assuming this function is defined\n",
    "    WIDTH = original.shape[0]\n",
    "    HEIGHT = original.shape[1]\n",
    "    # Convert the images to the CAM02-UCS color space and calculate the delta E loss\n",
    "    if original.shape[0] != recovered.shape[0] or original.shape[1] != recovered.shape[1]:\n",
    "        print(\"original shape:\", original.shape)\n",
    "        print(\"recovered shape:\", recovered.shape)\n",
    "        print(\"original and recovered shape do not match\")\n",
    "        original = original.reshape((WIDTH, HEIGHT, 3))\n",
    "        recovered = recovered.reshape((WIDTH, HEIGHT, 3))\n",
    "    original_lab = colorspacious.cspace_convert(np.array(original), 'sRGB1', 'CAM02-UCS').reshape((WIDTH,HEIGHT,3))\n",
    "    recovered_lab = colorspacious.cspace_convert(np.array(recovered), 'sRGB1', 'CAM02-UCS').reshape((WIDTH,HEIGHT,3))\n",
    "    delta_e = np.sqrt(np.sum((original_lab - recovered_lab)**2, axis=2))\n",
    "    # Plot the delta E loss in the third subplot\n",
    "    return delta_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'encode' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(image)\n\u001b[0;32m      9\u001b[0m image_numpy \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39mreshape((WIDTH, HEIGHT, \u001b[39m3\u001b[39m))\n\u001b[1;32m---> 10\u001b[0m pred_maps, encode_time \u001b[39m=\u001b[39m encode(image_numpy)\n\u001b[0;32m     11\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshape of pred_maps: \u001b[39m\u001b[39m{\u001b[39;00mpred_maps\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     12\u001b[0m Cm \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masarray(pred_maps[:,\u001b[39m0\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'encode' is not defined"
     ]
    }
   ],
   "source": [
    "# fig,ax = plt.subplots(5,5, figsize=(16,14))\n",
    "subjects_meta = ['m141_4k', 'm46_4k', 'm53_4k', 'm64_4k', 'm98_4k']\n",
    "idx = 0\n",
    "experiment_name = input(\"Enter experiment name: \")\n",
    "for image, folder_name in zip(images, names):\n",
    "    WIDTH = image.shape[0]\n",
    "    HEIGHT = image.shape[1]\n",
    "    image = np.asarray(image)\n",
    "    image_numpy = image.reshape((WIDTH, HEIGHT, 3))\n",
    "    pred_maps, encode_time = encode(image_numpy)\n",
    "    print(f\"shape of pred_maps: {pred_maps.shape}\")\n",
    "    Cm = np.asarray(pred_maps[:,0])\n",
    "    Ch = np.asarray(pred_maps[:,1])\n",
    "    Bm = np.asarray(pred_maps[:,2])\n",
    "    Bh = np.asarray(pred_maps[:,3])\n",
    "    T = np.asarray(pred_maps[:,4])\n",
    "    av_T = np.mean(T)\n",
    "    max_T = np.max(T)\n",
    "    min_T = np.min(T)\n",
    "    av_Cm = np.mean(Cm)\n",
    "    max_Cm = np.max(Cm)\n",
    "    min_Cm = np.min(Cm)\n",
    "    av_Ch = np.mean(Ch)\n",
    "    max_Ch = np.max(Ch)\n",
    "    min_Ch = np.min(Ch)\n",
    "    min_Bm = np.min(Bm)\n",
    "    max_Bm = np.max(Bm)\n",
    "    av_Bm = np.mean(Bm)\n",
    "    min_Bh = np.min(Bh)\n",
    "    max_Bh = np.max(Bh)\n",
    "    av_Bh = np.mean(Bh)\n",
    "    # result_string = f\"Cm: {av_Cm}, {max_Cm}, {min_Cm} | Ch: {av_Ch}, {max_Ch}, {min_Ch} | T: {av_T}, {max_T}, {min_T} | delta_e: {av_delta_e}, {max_delta_e}, {min_delta_e}\"\n",
    "    result_string = f\"Cm min: {min_Cm} Cm mean: {av_Cm}| Cm max: {max_Cm} | Ch min: {min_Ch} Ch mean: {av_Ch}| Ch max: {max_Ch} | T min: {min_T} T mean: {av_T}| T max: {max_T} | Bm min: {min_Bm} Bm mean: {av_Bm}| Bm max: {max_Bm} | Bh min: {min_Bh} Bh mean: {av_Bh}| Bh max: {max_Bh}\"\n",
    "    print(result_string)\n",
    "    pred_maps[:,0] = Cm\n",
    "    pred_maps[:,1] = Ch\n",
    "    pred_maps[:,2] = Bm\n",
    "    pred_maps[:,3] = Bh*0\n",
    "    pred_maps[:,4] = T\n",
    "    recovered, decode_time = decode(pred_maps)\n",
    "    print(f\"shape of recovered: {recovered.shape}\")\n",
    "    recovered = np.asarray(recovered).reshape((WIDTH, HEIGHT, 3))\n",
    "    # recovered_lab= colorspacious.cspace_convert(recovered, 'sRGB1', 'CAM02-UCS')\n",
    "    # recovered = np.asarray(decoded_increased_Cm).reshape((WIDTH, HEIGHT, 3))\n",
    "    plt.imshow(recovered)\n",
    "    plt.show()\n",
    "    #save the image \n",
    "    #print size of image\n",
    "    print(f\"size of image: {recovered.shape}\")\n",
    "    #max min pixel values\n",
    "    print(f\"max pixel value: {np.max(recovered)}\")\n",
    "    print(f\"min pixel value: {np.min(recovered)}\")\n",
    "    #clamp the values to 0-1\n",
    "    recovered = np.clip(recovered, 0, 1)\n",
    "    file_NAME = f\"{experiment_name}_{subjects_meta[idx]}.png\"\n",
    "    plt.imsave(file_NAME, recovered)\n",
    "    idx += 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu_20230406",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
