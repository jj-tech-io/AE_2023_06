{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AlreadyExistsError",
     "evalue": "Another metric with the same name already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAlreadyExistsError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mload_modules\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmy_config\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\joeli\\OneDrive\\Desktop\\AE_2023_06\\load_modules.py:27\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m \n\u001b[0;32m     26\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdatetime\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Lambda, BatchNormalization\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mclient\u001b[39;00m \u001b[39mimport\u001b[39;00m device_lib\n\u001b[0;32m     29\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mcolorspacious\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\keras\\api\\_v2\\keras\\__init__.py:10\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m__future__\u001b[39;00m \u001b[39mimport\u001b[39;00m print_function \u001b[39mas\u001b[39;00m _print_function\n\u001b[0;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39msys\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_sys\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n\u001b[0;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_v2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m __internal__\n\u001b[0;32m     12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapi\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_v2\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m activations\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\keras\\__init__.py:25\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m distribute\n\u001b[0;32m     24\u001b[0m \u001b[39m# See b/110718070#comment18 for more details about this import.\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m models\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39minput_layer\u001b[39;00m \u001b[39mimport\u001b[39;00m Input\n\u001b[0;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\keras\\models\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Copyright 2022 The TensorFlow Authors. All Rights Reserved.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# ==============================================================================\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Keras models API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mfunctional\u001b[39;00m \u001b[39mimport\u001b[39;00m Functional\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msequential\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtraining\u001b[39;00m \u001b[39mimport\u001b[39;00m Model\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\keras\\engine\\functional.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mwarnings\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m---> 25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer\n\u001b[0;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m base_layer_utils\n\u001b[0;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m input_layer \u001b[39mas\u001b[39;00m input_layer_module\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\keras\\engine\\base_layer.py:40\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m node \u001b[39mas\u001b[39;00m node_module\n\u001b[0;32m     39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m autocast_variable\n\u001b[1;32m---> 40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m loss_scale_optimizer\n\u001b[0;32m     41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m policy\n\u001b[0;32m     42\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaving\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msaved_model\u001b[39;00m \u001b[39mimport\u001b[39;00m layer_serialization\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\keras\\mixed_precision\\loss_scale_optimizer.py:18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[39m\"\"\"Contains the loss scaling optimizer class.\"\"\"\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend\n\u001b[1;32m---> 18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m optimizers\n\u001b[0;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmixed_precision\u001b[39;00m \u001b[39mimport\u001b[39;00m loss_scale \u001b[39mas\u001b[39;00m keras_loss_scale_module\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizer_v2\u001b[39;00m \u001b[39mimport\u001b[39;00m optimizer_v2\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\keras\\optimizers\\__init__.py:39\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m \u001b[39mimport\u001b[39;00m rmsprop\n\u001b[0;32m     38\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m \u001b[39mimport\u001b[39;00m sgd\n\u001b[1;32m---> 39\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m adadelta \u001b[39mas\u001b[39;00m adadelta_legacy\n\u001b[0;32m     40\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m adagrad \u001b[39mas\u001b[39;00m adagrad_legacy\n\u001b[0;32m     41\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m adam \u001b[39mas\u001b[39;00m adam_legacy\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\keras\\optimizers\\legacy\\adadelta.py:21\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcompat\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mv2\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m \u001b[39mimport\u001b[39;00m backend_config\n\u001b[1;32m---> 21\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlegacy\u001b[39;00m \u001b[39mimport\u001b[39;00m optimizer_v2\n\u001b[0;32m     23\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtf_export\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_export\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\keras\\optimizers\\legacy\\optimizer_v2.py:38\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[39m# isort: off\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutil\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mtf_export\u001b[39;00m \u001b[39mimport\u001b[39;00m keras_export\n\u001b[1;32m---> 38\u001b[0m keras_optimizers_gauge \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49m__internal__\u001b[39m.\u001b[39;49mmonitoring\u001b[39m.\u001b[39;49mBoolGauge(\n\u001b[0;32m     39\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39m/tensorflow/api/keras/optimizers\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mkeras optimizer usage\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mmethod\u001b[39;49m\u001b[39m\"\u001b[39;49m\n\u001b[0;32m     40\u001b[0m )\n\u001b[0;32m     42\u001b[0m _DEFAULT_VALID_DTYPES \u001b[39m=\u001b[39m \u001b[39mfrozenset\u001b[39m(\n\u001b[0;32m     43\u001b[0m     [\n\u001b[0;32m     44\u001b[0m         tf\u001b[39m.\u001b[39mfloat16,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     50\u001b[0m     ]\n\u001b[0;32m     51\u001b[0m )\n\u001b[0;32m     54\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_deduplicate_indexed_slices\u001b[39m(values, indices):\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\tensorflow\\python\\eager\\monitoring.py:360\u001b[0m, in \u001b[0;36mBoolGauge.__init__\u001b[1;34m(self, name, description, *labels)\u001b[0m\n\u001b[0;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, name, description, \u001b[39m*\u001b[39mlabels):\n\u001b[0;32m    353\u001b[0m   \u001b[39m\"\"\"Creates a new BoolGauge.\u001b[39;00m\n\u001b[0;32m    354\u001b[0m \n\u001b[0;32m    355\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[39m    *labels: The label list of the new metric.\u001b[39;00m\n\u001b[0;32m    359\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 360\u001b[0m   \u001b[39msuper\u001b[39;49m(BoolGauge, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mBoolGauge\u001b[39;49m\u001b[39m'\u001b[39;49m, _bool_gauge_methods,\n\u001b[0;32m    361\u001b[0m                                   \u001b[39mlen\u001b[39;49m(labels), name, description, \u001b[39m*\u001b[39;49mlabels)\n",
      "File \u001b[1;32mc:\\Users\\joeli\\anaconda3\\envs\\encoder_decoder\\lib\\site-packages\\tensorflow\\python\\eager\\monitoring.py:135\u001b[0m, in \u001b[0;36mMetric.__init__\u001b[1;34m(self, metric_name, metric_methods, label_length, *args)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[39mif\u001b[39;00m label_length \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metric_methods):\n\u001b[0;32m    132\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mCannot create \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m metric with label >= \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m    133\u001b[0m       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metric_name, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metric_methods)))\n\u001b[1;32m--> 135\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metric \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_metric_methods[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_label_length]\u001b[39m.\u001b[39;49mcreate(\u001b[39m*\u001b[39;49margs)\n",
      "\u001b[1;31mAlreadyExistsError\u001b[0m: Another metric with the same name already exists."
     ]
    }
   ],
   "source": [
    "from load_modules import *\n",
    "import my_config\n",
    "import time\n",
    "K.clear_session()\n",
    "os.environ[\"OPENCV_IO_ENABLE_OPENEXR\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "Found GPU at: /device:GPU:0\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "if my_config.USE_GPU:\n",
    "    physical_devices = tf.config.list_physical_devices('GPU')\n",
    "    #set memory amount to half of GPU\n",
    "    if len(physical_devices) > 0:\n",
    "        for device in physical_devices:\n",
    "            print(\"Device:\", device)\n",
    "    else:\n",
    "        print(\"No GPU devices found.\")\n",
    "    # Set GPU memory growth\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "                \n",
    "        except RuntimeError as e:\n",
    "            print(e)\n",
    "        # Set environment variable for GPU memory allocation\n",
    "    os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "    # Test for GPU device name\n",
    "    name = tf.test.gpu_device_name()\n",
    "    if name != '/device:GPU:0':\n",
    "        raise SystemError('GPU device not found')\n",
    "    print('Found GPU at: {}'.format(name))\n",
    "    # Print the number of available GPUs\n",
    "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "else:\n",
    "    print(\"No GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['m141_4k', 'm46_4k', 'm53_4k', 'm64_4k', 'm98_4k']\n",
      "models_4k\n",
      "TrainedModels\\316\\encoder.h5\n",
      "TrainedModels\\316\\decoder.h5\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Loaded models\n",
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 3)]               0         \n",
      "_________________________________________________________________\n",
      "encoder_dense_0 (Dense)      (None, 75)                300       \n",
      "_________________________________________________________________\n",
      "encoder_dense_2 (Dense)      (None, 75)                5700      \n",
      "_________________________________________________________________\n",
      "encoder_output (Dense)       (None, 5)                 380       \n",
      "=================================================================\n",
      "Total params: 6,380\n",
      "Trainable params: 6,380\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Encoder summary:None\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 5)]               0         \n",
      "_________________________________________________________________\n",
      "decoder_dense_0 (Dense)      (None, 75)                450       \n",
      "_________________________________________________________________\n",
      "decoder_dense_2 (Dense)      (None, 75)                5700      \n",
      "_________________________________________________________________\n",
      "decoder_output (Dense)       (None, 3)                 228       \n",
      "=================================================================\n",
      "Total params: 6,378\n",
      "Trainable params: 6,378\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Decoder summary:None\n"
     ]
    }
   ],
   "source": [
    "image_paths = os.listdir(my_config.IMAGE_FOLDER)\n",
    "images = []\n",
    "names = []\n",
    "for image_path in image_paths:\n",
    "    folder_name = image_path.split('.')[0]\n",
    "    names.append(folder_name)\n",
    "    image_path = os.path.join(my_config.IMAGE_FOLDER, image_path)\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = np.array(image)\n",
    "    if np.max(image) > 1:\n",
    "        image = image/255.0\n",
    "    images.append(image)\n",
    "print(names)\n",
    "all_model_paths = []\n",
    "print(my_config.IMAGE_FOLDER)\n",
    "print(my_config.ENCODER_PATH)\n",
    "print(my_config.DECODER_PATH)\n",
    "\n",
    "encoder = load_model(my_config.ENCODER_PATH)\n",
    "decoder = load_model(my_config.DECODER_PATH)\n",
    "print(\"Loaded models\")\n",
    "print(\"Encoder summary:\" + str(encoder.summary()))\n",
    "print(\"Decoder summary:\" + str(decoder.summary()))\n",
    "def encode(img):\n",
    "    image = np.asarray(img).reshape(-1,3).astype('float32')\n",
    "    # pred_maps = encoder.predict(image)\n",
    "    start = time.time()\n",
    "    pred_maps = None\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        pred_maps = encoder.predict_on_batch(image)\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    return pred_maps, elapsed\n",
    " \n",
    "def decode(encoded):\n",
    "    # recovered = decoder.predict(encoded)\n",
    "    start = time.time()\n",
    "    recovered = None\n",
    "    with tf.device('/device:GPU:0'):\n",
    "        recovered = decoder.predict_on_batch(encoded)\n",
    "    end = time.time()\n",
    "    elapsed = end - start\n",
    "    # recovered = np.clip(recovered, 0, 1)\n",
    "    return recovered, elapsed\n",
    "def calculate_deltaE(original, recovered):  # assuming this function is defined\n",
    "    WIDTH = original.shape[0]\n",
    "    HEIGHT = original.shape[1]\n",
    "    # Convert the images to the CAM02-UCS color space and calculate the delta E loss\n",
    "    if original.shape[0] != recovered.shape[0] or original.shape[1] != recovered.shape[1]:\n",
    "        print(\"original shape:\", original.shape)\n",
    "        print(\"recovered shape:\", recovered.shape)\n",
    "        print(\"original and recovered shape do not match\")\n",
    "        original = original.reshape((WIDTH, HEIGHT, 3))\n",
    "        recovered = recovered.reshape((WIDTH, HEIGHT, 3))\n",
    "    original_lab = colorspacious.cspace_convert(np.array(original), 'sRGB1', 'CAM02-UCS').reshape((WIDTH,HEIGHT,3))\n",
    "    recovered_lab = colorspacious.cspace_convert(np.array(recovered), 'sRGB1', 'CAM02-UCS').reshape((WIDTH,HEIGHT,3))\n",
    "    delta_e = np.sqrt(np.sum((original_lab - recovered_lab)**2, axis=2))\n",
    "    # Plot the delta E loss in the third subplot\n",
    "    return delta_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(5,5, figsize=(16,14))\n",
    "subjects_meta = ['m141_4k', 'm46_4k', 'm53_4k', 'm64_4k', 'm98_4k']\n",
    "idx = 0\n",
    "\n",
    "for image, folder_name in zip(images, names):\n",
    "    WIDTH = image.shape[0]\n",
    "    HEIGHT = image.shape[1]\n",
    "    image = np.asarray(image)\n",
    "    image_numpy = image.reshape((WIDTH, HEIGHT, 3))\n",
    "    pred_maps, encode_time = encode(image_numpy)\n",
    "    print(f\"shape of pred_maps: {pred_maps.shape}\")\n",
    "    Cm = np.asarray(pred_maps[:,0])\n",
    "    Ch = np.asarray(pred_maps[:,1])\n",
    "    Bm = np.asarray(pred_maps[:,2])\n",
    "    Bh = np.asarray(pred_maps[:,3])\n",
    "    T = np.asarray(pred_maps[:,4])\n",
    "    av_T = np.mean(T)\n",
    "    max_T = np.max(T)\n",
    "    min_T = np.min(T)\n",
    "    av_Cm = np.mean(Cm)\n",
    "    max_Cm = np.max(Cm)\n",
    "    min_Cm = np.min(Cm)\n",
    "    av_Ch = np.mean(Ch)\n",
    "    max_Ch = np.max(Ch)\n",
    "    min_Ch = np.min(Ch)\n",
    "    min_Bm = np.min(Bm)\n",
    "    max_Bm = np.max(Bm)\n",
    "    av_Bm = np.mean(Bm)\n",
    "    min_Bh = np.min(Bh)\n",
    "    max_Bh = np.max(Bh)\n",
    "    av_Bh = np.mean(Bh)\n",
    "    # result_string = f\"Cm: {av_Cm}, {max_Cm}, {min_Cm} | Ch: {av_Ch}, {max_Ch}, {min_Ch} | T: {av_T}, {max_T}, {min_T} | delta_e: {av_delta_e}, {max_delta_e}, {min_delta_e}\"\n",
    "    result_string = f\"Cm min: {min_Cm} Cm mean: {av_Cm}| Cm max: {max_Cm} | Ch min: {min_Ch} Ch mean: {av_Ch}| Ch max: {max_Ch} | T min: {min_T} T mean: {av_T}| T max: {max_T} | Bm min: {min_Bm} Bm mean: {av_Bm}| Bm max: {max_Bm} | Bh min: {min_Bh} Bh mean: {av_Bh}| Bh max: {max_Bh}\"\n",
    "    print(result_string)\n",
    "    pred_maps[:,0] = Cm*0.9\n",
    "    pred_maps[:,1] = Ch*0.9\n",
    "    pred_maps[:,2] = Bm\n",
    "    pred_maps[:,3] = Bh*0.8\n",
    "    pred_maps[:,4] = T*0.9\n",
    "    recovered, decode_time = decode(pred_maps)\n",
    "    print(f\"shape of recovered: {recovered.shape}\")\n",
    "    recovered = np.asarray(recovered).reshape((WIDTH, HEIGHT, 3))\n",
    "    # recovered_lab= colorspacious.cspace_convert(recovered, 'sRGB1', 'CAM02-UCS')\n",
    "    # recovered = np.asarray(decoded_increased_Cm).reshape((WIDTH, HEIGHT, 3))\n",
    "    plt.imshow(recovered)\n",
    "    plt.show()\n",
    "    #save the image \n",
    "    #print size of image\n",
    "    print(f\"size of image: {recovered.shape}\")\n",
    "    #max min pixel values\n",
    "    print(f\"max pixel value: {np.max(recovered)}\")\n",
    "    print(f\"min pixel value: {np.min(recovered)}\")\n",
    "    #clamp the values to 0-1\n",
    "    recovered = np.clip(recovered, 0, 1)\n",
    "    # experiment_name = input(\"Enter experiment name: \")\n",
    "    # file_NAME = f\"{experiment_name}_{subjects_meta[idx]}.png\"\n",
    "    # plt.imsave(file_NAME, recovered)\n",
    "    idx += 1\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu_20230406",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
